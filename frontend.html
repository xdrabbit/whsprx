<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document RAG Search</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 2rem;
            background-color: #f7f7f7;
            color: #333;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .container {
            width: 100%;
            max-width: 800px;
            background-color: #fff;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        h1, h2 {
            text-align: center;
            color: #111;
        }
        .section {
            margin-bottom: 2rem;
            border-bottom: 1px solid #eee;
            padding-bottom: 2rem;
        }
        .section:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }
        label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 600;
        }
        input[type="file"], input[type="text"], select {
            width: 100%;
            padding: 0.75rem;
            border: 1px solid #ccc;
            border-radius: 4px;
            box-sizing: border-box;
            margin-bottom: 1rem;
        }
        button {
            background-color: #007aff;
            color: white;
            padding: 0.75rem 1.5rem;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 1rem;
            width: 100%;
            transition: background-color 0.2s;
        }
        button:hover {
            background-color: #005ecb;
        }
        #status, #rag-status, #pixverse-status {
            margin-top: 1rem;
            text-align: center;
            font-style: italic;
            color: #666;
        }
        #results-container, #rag-container, #generated-video-container {
            margin-top: 1.5rem;
        }
        .result-item, .context-item {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 4px;
        }
        .result-item p, .context-item p {
            margin: 0 0 0.5rem 0;
        }
        .result-item .meta, .context-item .meta {
            font-size: 0.85rem;
            color: #888;
        }
        #rag-answer {
            white-space: pre-wrap; /* Preserve whitespace and newlines */
            line-height: 1.6;
        }
        .attribution {
            font-size: 0.8rem;
            color: #777;
            margin-top: 1.5rem;
            text-align: right;
            border-top: 1px solid #cce4ff;
            padding-top: 1rem;
        }
        #visualize-section {
            display: none; /* Hidden by default */
            margin-top: 2rem;
            padding-top: 2rem;
            border-top: 1px solid #eee;
        }
        #generated-image-container {
            margin-top: 1.5rem;
            text-align: center;
        }
        #generated-image {
            max-width: 100%;
            border-radius: 4px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        /* Ghost Guide Mode Styles */
        #ghost-guide-btn {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            box-shadow: 0 4px 20px rgba(102, 126, 234, 0.4);
            z-index: 999;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        #ghost-guide-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 6px 30px rgba(102, 126, 234, 0.6);
        }
        
        #ghost-guide-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            z-index: 1000;
            display: none;
            opacity: 0;
            transition: opacity 0.5s ease-in-out;
        }
        
        #ghost-guide-overlay.visible {
            opacity: 1;
        }
        
        #ghost-guide-content {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            max-width: 800px;
            width: 90%;
            max-height: 80vh;
            overflow-y: auto;
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            border-radius: 20px;
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
            padding: 2rem;
            color: #fff;
        }
        
        #ghost-guide-content h2 {
            margin-top: 0;
            font-size: 2rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        #ghost-guide-content h3 {
            color: #667eea;
            margin-top: 1.5rem;
            font-size: 1.3rem;
        }
        
        #ghost-guide-content p, #ghost-guide-content ul {
            color: rgba(255, 255, 255, 0.95);
            line-height: 1.6;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.3);
        }
        
        #ghost-guide-content ul {
            list-style: none;
            padding-left: 0;
        }
        
        #ghost-guide-content li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
        }
        
        #ghost-guide-content li:before {
            content: "‚ú®";
            position: absolute;
            left: 0;
        }
        
        #ghost-guide-close {
            position: absolute;
            top: 1rem;
            right: 1rem;
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 1.5rem;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }
        
        #ghost-guide-close:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: rotate(90deg);
        }
        
        .feature-section {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
    </style>
</head>
<body>
    <!-- Ghost Guide Button -->
    <button id="ghost-guide-btn" title="Ghost Guide Mode (?)">üëª</button>
    
    <!-- Ghost Guide Overlay -->
    <div id="ghost-guide-overlay">
        <div id="ghost-guide-content">
            <button id="ghost-guide-close">√ó</button>
            <h2>üëª Ghost Guide Mode</h2>
            <p style="font-size: 1.1rem; opacity: 0.9;">Your helpful AI assistant that appears when you need it, and fades away when you're focused.</p>
            
            <div class="feature-section">
                <h3>üìÑ Document Upload & Search</h3>
                <ul>
                    <li>Upload text files to build your knowledge base</li>
                    <li>Search semantically - finds meaning, not just keywords</li>
                    <li>View source documents with metadata</li>
                </ul>
            </div>
            
            <div class="feature-section">
                <h3>ü§ñ RAG (Retrieval-Augmented Generation)</h3>
                <ul>
                    <li>Ask questions about your uploaded documents</li>
                    <li>AI retrieves relevant context and generates answers</li>
                    <li>Choose your LLM model from the dropdown</li>
                    <li>See which documents informed the answer</li>
                </ul>
            </div>
            
            <div class="feature-section">
                <h3>üé® AI Image Generation</h3>
                <ul>
                    <li>Use the AI Art Director to craft detailed prompts</li>
                    <li>Select ComfyUI models dynamically</li>
                    <li>Generate images at 512x512 for faster results</li>
                    <li>Real-time progress via WebSocket</li>
                    <li><strong>üí¨ Chat About Images:</strong> After generation, chat with AI about your image!</li>
                </ul>
                
                <h4 style="margin: 1rem 0 0.5rem 0; color: #fff;">üí¨ Image Chat Feature:</h4>
                <ol style="list-style: decimal; padding-left: 2rem; margin: 0;">
                    <li style="padding-left: 0;"><strong>Generate an image</strong> using the Visualize section</li>
                    <li style="padding-left: 0;"><strong>Chat interface appears</strong> automatically below the image</li>
                    <li style="padding-left: 0;"><strong>Ask questions:</strong> "What colors?", "Describe this", "What's the mood?"</li>
                    <li style="padding-left: 0;"><strong>Get suggestions:</strong> "How can I improve this?"</li>
                    <li style="padding-left: 0;"><strong>Choose vision model:</strong> LLaVA or BakLLaVA</li>
                    <li style="padding-left: 0;"><strong>Iterate:</strong> Use AI suggestions to refine and regenerate</li>
                </ol>
            </div>
            
            <div class="feature-section">
                <h3>üé¨ PixVerse Video Generation</h3>
                <ul>
                    <li><strong>Text-to-Video:</strong> Describe your scene, get a video</li>
                    <li><strong>Image-to-Video:</strong> Upload image + motion prompt</li>
                    <li><strong>Advanced Options:</strong> Duration, quality, motion mode, camera movement, seed</li>
                    <li>Monitor credit balance with visual gauge</li>
                </ul>
            </div>
            
            <div class="feature-section">
                <h3>üé• Video Actions (After Generation)</h3>
                <ul>
                    <li><strong>Extend Video:</strong> Add 10 more seconds to continue the story</li>
                    <li><strong>Lip Sync:</strong> Make characters speak with synchronized lip movements</li>
                </ul>
                
                <h4 style="margin: 1rem 0 0.5rem 0; color: #fff;">üé§ Lip Sync Step-by-Step:</h4>
                <ol style="list-style: decimal; padding-left: 2rem; margin: 0;">
                    <li style="padding-left: 0;"><strong>Generate a video</strong> with a character/person visible</li>
                    <li style="padding-left: 0;"><strong>Wait for completion</strong> - Video Actions section appears</li>
                    <li style="padding-left: 0;"><strong>Choose mode:</strong>
                        <ul style="list-style: disc; padding-left: 1.5rem;">
                            <li style="padding-left: 0;"><strong>Text-to-Speech:</strong> Type text, select voice (15 options), submit</li>
                            <li style="padding-left: 0;"><strong>Upload Audio:</strong> Select audio file, submit</li>
                        </ul>
                    </li>
                    <li style="padding-left: 0;"><strong>System generates</strong> new video with lip-synced speech</li>
                    <li style="padding-left: 0;"><strong>Result:</strong> Character's lips match the audio perfectly!</li>
                </ol>
            </div>
            
            <div class="feature-section">
                <h3>üé§ Text-to-Speech</h3>
                <ul>
                    <li>Convert any text to natural speech</li>
                    <li>Multiple voice options via ElevenLabs</li>
                    <li>Download as MP3</li>
                </ul>
            </div>
            
            <div class="feature-section">
                <h3>üí° Ghost Guide Tips</h3>
                <ul>
                    <li><strong>Left-click üëª</strong> anytime for help</li>
                    <li><strong>Right-click üëª</strong> to dismiss for entire session</li>
                    <li>Guide appears automatically after 2s of inactivity</li>
                    <li>Fades away when you move mouse or type</li>
                    <li>Press <strong>ESC</strong> to dismiss temporarily</li>
                </ul>
            </div>
        </div>
    </div>
    
    <div class="container">
        <h1>Document RAG Search</h1>

        <div class="section">
            <h2>1. Upload a Document</h2>
            <form id="upload-form">
                <label for="file-input">Select a .txt file to process:</label>
                <input id="file-input" type="file" name="file" accept=".txt">
                <button type="submit">Upload and Index</button>
            </form>
            <div id="status"></div>
        </div>

        <div class="section">
            <h2>2. Query with RAG</h2>
            <form id="rag-form">
                <label for="rag-query-input">Your Question:</label>
                <input id="rag-query-input" type="text" placeholder="e.g., What did Alice follow down the hole?">
                
                <label for="model-select">Choose an LLM:</label>
                <select id="model-select" name="model">
                    <!-- Models will be populated dynamically -->
                </select>
                
                <button type="submit">Get Answer</button>
            </form>
            <div id="rag-status"></div>
            <div id="rag-container">
                <h3>Generative Answer</h3>
                <div id="rag-answer-container">
                    <div id="rag-answer">(Your answer will appear here)</div>
                    <div id="tts-controls" style="display: none; margin-top: 1rem; align-items: center; gap: 1rem;">
                        <select id="voice-select" name="voice" style="flex-grow: 1;"></select>
                        <button id="listen-button">Listen</button>
                        <audio id="audio-player" controls style="display: none; width: 100%; margin-top: 0.5rem;"></audio>
                    </div>
                </div>
                
                <div id="visualize-section">
                    <h3>Visualize the Answer</h3>
                    <form id="visualize-form">
                        <label for="comfy-model-input">Choose an Image Model:</label>
                        <input id="comfy-model-input" list="comfy-models-list" placeholder="e.g., sd_xl_base_1.0.safetensors">
                        <datalist id="comfy-models-list">
                            <!-- ComfyUI models will be populated here -->
                        </datalist>
                        <label for="artistic-direction-input" style="margin-top: 1rem;">Artistic Direction (Optional):</label>
                        <textarea id="artistic-direction-input" rows="3" placeholder="e.g., in the style of a dark fantasy painting, cinematic lighting"></textarea>
                        <button type="submit">Generate Image</button>
                    </form>
                    <div id="visualize-status"></div>
                    <div id="generated-image-container"></div>
                    
                    <!-- AI Image Chat Interface -->
                    <div id="image-chat-section" style="display: none; margin-top: 1.5rem; border-top: 2px solid #667eea; padding-top: 1.5rem;">
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                            <h4 style="margin: 0; color: #667eea;">üí¨ Chat About This Image</h4>
                            <select id="vision-model-select" style="padding: 0.3rem; border-radius: 4px; border: 1px solid #ddd;">
                                <option value="llava:latest">LLaVA</option>
                                <option value="bakllava:latest">BakLLaVA</option>
                            </select>
                        </div>
                        <div id="chat-messages" style="max-height: 300px; overflow-y: auto; background: #f8f9fa; padding: 1rem; border-radius: 8px; margin-bottom: 1rem; border: 1px solid #e0e0e0;">
                            <p style="color: #666; font-size: 0.9rem; text-align: center; margin: 2rem 0;">Ask me anything about this image! üé®</p>
                        </div>
                        <form id="image-chat-form" style="display: flex; gap: 0.5rem;">
                            <input type="text" id="chat-message-input" placeholder="e.g., What colors are dominant? Can you describe this?" style="flex: 1; padding: 0.8rem; border-radius: 4px; border: 1px solid #ddd;">
                            <button type="submit" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; padding: 0.8rem 1.5rem; border-radius: 4px; cursor: pointer; font-weight: 600;">Send</button>
                        </form>
                        <div id="chat-status" style="font-size: 0.85rem; color: #666; margin-top: 0.5rem;"></div>
                    </div>
                </div>

                <h3>Retrieved Context</h3>
                <div id="rag-context"></div>
            </div>
        </div>

        <!-- PixVerse Video Generation -->
        <div class="section">
            <h2>PixVerse Video Generation</h2>
            
            <!-- Credit Balance Display -->
            <div id="pixverse-credits" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1rem; border-radius: 8px; margin-bottom: 1.5rem; color: white;">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                    <span style="font-weight: 600; font-size: 0.9rem;">‚ö° PixVerse Credits</span>
                    <button onclick="fetchPixverseCredits()" style="background: rgba(255,255,255,0.2); border: none; color: white; padding: 0.3rem 0.8rem; border-radius: 4px; cursor: pointer; font-size: 0.85rem;">‚Üª Refresh</button>
                </div>
                <div style="display: flex; gap: 1.5rem; flex-wrap: wrap;">
                    <div>
                        <div style="font-size: 0.75rem; opacity: 0.9; margin-bottom: 0.2rem;">Monthly Credits</div>
                        <div id="credit-monthly" style="font-size: 1.5rem; font-weight: bold;">--</div>
                    </div>
                    <div>
                        <div style="font-size: 0.75rem; opacity: 0.9; margin-bottom: 0.2rem;">Package Credits</div>
                        <div id="credit-package" style="font-size: 1.5rem; font-weight: bold;">--</div>
                    </div>
                </div>
                <div style="margin-top: 0.8rem; background: rgba(255,255,255,0.2); height: 8px; border-radius: 4px; overflow: hidden;">
                    <div id="credit-bar" style="height: 100%; background: #4ade80; width: 0%; transition: width 0.5s ease;"></div>
                </div>
                <div id="credit-status" style="font-size: 0.75rem; margin-top: 0.5rem; opacity: 0.9;">Loading credits...</div>
            </div>
            
            <form id="pixverse-form">
                <label for="pixverse-prompt-input">Video Prompt:</label>
                <input type="text" id="pixverse-prompt-input" placeholder="e.g., a cat playing a piano">
                <button type="submit">Generate Video</button>
            </form>
            
            <!-- Image to Video Form -->
            <form id="pixverse-image-form" style="margin-top: 2rem; padding-top: 2rem; border-top: 1px solid #eee;">
                <h3 style="margin-top: 0;">Image to Video</h3>
                <label for="pixverse-image-input">Upload Image:</label>
                <input type="file" id="pixverse-image-input" accept="image/*" style="margin-bottom: 1rem;">
                
                <label for="pixverse-image-prompt-input">Motion Prompt:</label>
                <input type="text" id="pixverse-image-prompt-input" placeholder="e.g., camera slowly zooms in">
                
                <!-- Advanced Options Collapsible -->
                <div style="margin: 1.5rem 0;">
                    <button type="button" id="toggle-advanced" style="background: #f0f0f0; color: #333; border: 1px solid #ccc; padding: 0.5rem 1rem; border-radius: 4px; cursor: pointer; width: 100%; text-align: left; display: flex; justify-content: space-between; align-items: center;">
                        <span>‚öôÔ∏è Advanced Options</span>
                        <span id="toggle-icon">‚ñº</span>
                    </button>
                    <div id="advanced-options" style="display: none; margin-top: 1rem; padding: 1rem; background: #f9f9f9; border-radius: 4px;">
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem;">
                            <div>
                                <label for="duration-select">Duration:</label>
                                <select id="duration-select">
                                    <option value="5">5 seconds</option>
                                    <option value="10">10 seconds</option>
                                </select>
                            </div>
                            <div>
                                <label for="quality-select">Quality:</label>
                                <select id="quality-select">
                                    <option value="540p" selected>540p (Faster)</option>
                                    <option value="720p">720p</option>
                                    <option value="1080p">1080p (Best)</option>
                                </select>
                            </div>
                            <div>
                                <label for="motion-mode-select">Motion Mode:</label>
                                <select id="motion-mode-select">
                                    <option value="normal" selected>Normal</option>
                                    <option value="fast">Fast</option>
                                    <option value="slow">Slow</option>
                                </select>
                            </div>
                            <div>
                                <label for="camera-movement-select">Camera Movement:</label>
                                <select id="camera-movement-select">
                                    <option value="none" selected>None</option>
                                    <option value="zoom_in">Zoom In</option>
                                    <option value="zoom_out">Zoom Out</option>
                                    <option value="pan_left">Pan Left</option>
                                    <option value="pan_right">Pan Right</option>
                                    <option value="tilt_up">Tilt Up</option>
                                    <option value="tilt_down">Tilt Down</option>
                                </select>
                            </div>
                            <div style="grid-column: span 2;">
                                <label for="seed-input">Seed (0 for random):</label>
                                <input type="number" id="seed-input" value="0" min="0">
                            </div>
                        </div>
                    </div>
                </div>
                
                <button type="submit">Generate Video from Image</button>
            </form>
            
            <div id="pixverse-status"></div>
            <div id="generated-video-container"></div>
            
            <!-- Video Actions (Extend & Lip Sync) - Hidden until video is ready -->
            <div id="video-actions" style="display: none; margin-top: 2rem; padding-top: 2rem; border-top: 1px solid #eee;">
                <h3>Video Actions</h3>
                
                <!-- Extend Video Form -->
                <div style="margin-bottom: 2rem; padding: 1rem; background: #f0f8ff; border-radius: 4px;">
                    <h4 style="margin-top: 0;">üé¨ Extend Video</h4>
                    <p style="font-size: 0.9rem; color: #666;">Continue the story by extending your video by 10 more seconds</p>
                    <form id="extend-video-form">
                        <label for="extend-prompt">Extension Prompt:</label>
                        <input type="text" id="extend-prompt" placeholder="e.g., camera pans to reveal a mountain" required>
                        <button type="submit">Extend Video</button>
                    </form>
                </div>
                
                <!-- Lip Sync Form -->
                <div style="padding: 1rem; background: #fff5f0; border-radius: 4px;">
                    <h4 style="margin-top: 0;">üé§ Add Lip Sync</h4>
                    <p style="font-size: 0.9rem; color: #666;">Make characters speak with synchronized lip movements</p>
                    <form id="lip-sync-form">
                        <div id="lip-sync-mode-toggle" style="margin-bottom: 1rem;">
                            <label style="margin-right: 1rem;">
                                <input type="radio" name="lipSyncMode" value="tts" checked> Text-to-Speech
                            </label>
                            <label>
                                <input type="radio" name="lipSyncMode" value="audio"> Upload Audio
                            </label>
                        </div>
                        
                        <!-- TTS Mode -->
                        <div id="tts-mode" style="display: block;">
                            <label for="tts-text">Speech Text:</label>
                            <textarea id="tts-text" placeholder="e.g., Hello! Welcome to my world." rows="3"></textarea>
                            
                            <label for="tts-speaker">Voice:</label>
                            <select id="tts-speaker">
                                <option value="auto">Auto (Detect from video)</option>
                            </select>
                        </div>
                        
                        <!-- Audio Upload Mode -->
                        <div id="audio-mode" style="display: none;">
                            <label for="audio-file">Upload Audio File:</label>
                            <input type="file" id="audio-file" accept="audio/*">
                            <div id="audio-upload-status" style="margin-top: 0.5rem; font-size: 0.9rem;"></div>
                        </div>
                        
                        <button type="submit">Generate Lip Sync</button>
                    </form>
                </div>
            </div>
        </div>
    </div>

    <script>
        // --- Ghost Guide Mode ---
        let ghostGuideTimeout;
        let userActivityTimeout;
        const ghostGuideOverlay = document.getElementById('ghost-guide-overlay');
        const ghostGuideBtn = document.getElementById('ghost-guide-btn');
        const ghostGuideClose = document.getElementById('ghost-guide-close');
        let isGhostGuideManuallyOpened = false;
        let ghostGuideDismissed = false;  // Track if user dismissed for session
        
        function showGhostGuide() {
            if (ghostGuideDismissed) return;  // Don't auto-show if dismissed for session
            ghostGuideOverlay.style.display = 'block';
            // Trigger reflow to enable transition
            ghostGuideOverlay.offsetHeight;
            ghostGuideOverlay.classList.add('visible');
        }
        
        function hideGhostGuide() {
            ghostGuideOverlay.classList.remove('visible');
            setTimeout(() => {
                ghostGuideOverlay.style.display = 'none';
            }, 500); // Match transition duration
        }
        
        function resetUserActivityTimer() {
            // Clear existing timeout
            clearTimeout(userActivityTimeout);
            
            // If guide is visible and not manually opened, hide it
            if (ghostGuideOverlay.classList.contains('visible') && !isGhostGuideManuallyOpened) {
                hideGhostGuide();
            }
            
            // Set new timeout to show guide after 2 seconds of inactivity
            userActivityTimeout = setTimeout(() => {
                if (!isGhostGuideManuallyOpened) {
                    showGhostGuide();
                }
            }, 2000);
        }
        
        // Left-click to open, right-click to dismiss for session
        ghostGuideBtn.addEventListener('click', () => {
            isGhostGuideManuallyOpened = true;
            ghostGuideDismissed = false;  // Manual click reactivates Ghost Guide
            clearTimeout(userActivityTimeout);
            ghostGuideOverlay.style.display = 'block';
            ghostGuideOverlay.offsetHeight;
            ghostGuideOverlay.classList.add('visible');
        });
        
        ghostGuideBtn.addEventListener('contextmenu', (e) => {
            e.preventDefault();  // Prevent default context menu
            ghostGuideDismissed = true;
            isGhostGuideManuallyOpened = false;
            hideGhostGuide();
            console.log('üëª Ghost Guide dismissed for session. Left-click üëª to reactivate.');
        });
        
        // Close button
        ghostGuideClose.addEventListener('click', () => {
            isGhostGuideManuallyOpened = false;
            hideGhostGuide();
            resetUserActivityTimer();
        });
        
        // Close on ESC key
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && ghostGuideOverlay.classList.contains('visible')) {
                isGhostGuideManuallyOpened = false;
                hideGhostGuide();
                resetUserActivityTimer();
            }
        });
        
        // Close on overlay click (not content)
        ghostGuideOverlay.addEventListener('click', (e) => {
            if (e.target === ghostGuideOverlay) {
                isGhostGuideManuallyOpened = false;
                hideGhostGuide();
                resetUserActivityTimer();
            }
        });
        
        // Track user activity
        document.addEventListener('mousemove', resetUserActivityTimer);
        document.addEventListener('keydown', resetUserActivityTimer);
        document.addEventListener('click', resetUserActivityTimer);
        document.addEventListener('scroll', resetUserActivityTimer);
        
        // Start the inactivity timer on page load
        resetUserActivityTimer();
        
        // --- Populate Ollama Models ---
        document.addEventListener('DOMContentLoaded', async () => {
            const modelSelect = document.getElementById('model-select');
            const ragStatus = document.getElementById('rag-status');
            const comfyModelsList = document.getElementById('comfy-models-list');
            try {
                ragStatus.textContent = 'Fetching available LLMs...';
                const response = await fetch('/api/ollama/models');
                if (!response.ok) {
                    throw new Error(`Failed to fetch models: ${response.statusText}`);
                }
                const data = await response.json();
                const models = data.models;

                if (models && models.length > 0) {
                    modelSelect.innerHTML = ''; // Clear any previous options
                    models.forEach(modelName => {
                        const option = document.createElement('option');
                        option.value = modelName;
                        option.textContent = modelName;
                        modelSelect.appendChild(option);
                    });
                    ragStatus.textContent = 'LLMs loaded. Ready to answer questions.';
                } else {
                    ragStatus.textContent = 'No Ollama models found. Please ensure Ollama is running and has models available.';
                    modelSelect.innerHTML = '<option>No models available</option>';
                }
            } catch (error) {
                console.error('Error fetching Ollama models:', error);
                ragStatus.textContent = `Error: ${error.message}. Is Ollama running?`;
                modelSelect.innerHTML = '<option>Failed to load models</option>';
            }

            // --- Populate ComfyUI Models ---
            try {
                const comfyResponse = await fetch('/api/comfyui/models');
                if (!comfyResponse.ok) {
                    throw new Error(`Failed to fetch ComfyUI models: ${comfyResponse.statusText}`);
                }
                const comfyData = await comfyResponse.json();
                const comfyModels = comfyData.models;

                if (comfyModels && comfyModels.length > 0) {
                    comfyModelsList.innerHTML = ''; // Clear any previous options
                    comfyModels.forEach(modelName => {
                        const option = document.createElement('option');
                        option.value = modelName;
                        option.textContent = modelName;
                        comfyModelsList.appendChild(option);
                    });
                } else {
                    // Add a default option or leave empty
                    const option = document.createElement('option');
                    option.value = '';
                    option.textContent = 'No models available';
                    comfyModelsList.appendChild(option);
                }
            } catch (error) {
                console.error('Error fetching ComfyUI models:', error);
                const option = document.createElement('option');
                option.value = '';
                option.textContent = 'Failed to load models';
                comfyModelsList.appendChild(option);
            }
            
            // --- Fetch PixVerse Credits ---
            fetchPixverseCredits();
        });
        
        // Function to fetch and display PixVerse credits
        async function fetchPixverseCredits() {
            try {
                const response = await fetch('/api/pixverse/credits');
                const data = await response.json();
                
                if (response.ok) {
                    const monthly = data.credit_monthly || 0;
                    const package = data.credit_package || 0;
                    const total = monthly + package;
                    
                    document.getElementById('credit-monthly').textContent = monthly.toLocaleString();
                    document.getElementById('credit-package').textContent = package.toLocaleString();
                    
                    // Update progress bar (assume 1M is full tank)
                    const percentage = Math.min((total / 1000000) * 100, 100);
                    document.getElementById('credit-bar').style.width = percentage + '%';
                    
                    // Update status message
                    let statusMsg = '';
                    if (total > 500000) {
                        statusMsg = 'üü¢ Tank is full! Generate away!';
                        document.getElementById('credit-bar').style.background = '#4ade80';
                    } else if (total > 100000) {
                        statusMsg = 'üü° Credits looking good';
                        document.getElementById('credit-bar').style.background = '#fbbf24';
                    } else {
                        statusMsg = 'üî¥ Running low - time to fill up!';
                        document.getElementById('credit-bar').style.background = '#ef4444';
                    }
                    document.getElementById('credit-status').textContent = statusMsg;
                } else {
                    document.getElementById('credit-status').textContent = 'Failed to load credits';
                }
            } catch (error) {
                console.error('Error fetching credits:', error);
                document.getElementById('credit-status').textContent = 'Error loading credits';
            }
        }

        // --- Handle File Upload ---
        const uploadForm = document.getElementById('upload-form');
        const statusDiv = document.getElementById('status');
        uploadForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            const formData = new FormData(uploadForm);
            const fileInput = document.getElementById('file-input');
            
            if (!fileInput.files || fileInput.files.length === 0) {
                statusDiv.textContent = 'Please select a file first.';
                statusDiv.style.color = 'red';
                return;
            }

            statusDiv.textContent = 'Uploading and processing...';
            statusDiv.style.color = '#333';

            try {
                const response = await fetch('/upload', {
                    method: 'POST',
                    body: formData,
                });
                const result = await response.json();
                if (response.ok) {
                    statusDiv.textContent = result.message;
                    statusDiv.style.color = 'green';
                } else {
                    throw new Error(result.detail || 'An unknown error occurred.');
                }
            } catch (error) {
                statusDiv.textContent = `Error: ${error.message}`;
                statusDiv.style.color = 'red';
            }
        });

        // --- Handle RAG Query ---
        const ragForm = document.getElementById('rag-form');
        const ragStatus = document.getElementById('rag-status');
        const ragAnswerContainer = document.getElementById('rag-answer-container');
        const ragAnswerDiv = document.getElementById('rag-answer');
        const ragContextDiv = document.getElementById('rag-context');
        const visualizeSection = document.getElementById('visualize-section');
        const ttsControls = document.getElementById('tts-controls');
        const listenButton = document.getElementById('listen-button');
        const audioPlayer = document.getElementById('audio-player');
        const voiceSelect = document.getElementById('voice-select');
        const generatedImageContainer = document.getElementById('generated-image-container');

        ragForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            const query = document.getElementById('rag-query-input').value;
            const selectedModel = document.getElementById('model-select').value;

            if (!query) {
                ragStatus.textContent = 'Please enter a question.';
                return;
            }
            if (!selectedModel || selectedModel === 'No models available' || selectedModel === 'Failed to load models') {
                ragStatus.textContent = 'Please select a valid LLM.';
                return;
            }

            ragStatus.textContent = `Thinking with ${selectedModel}...`;
            ragAnswerDiv.textContent = '(Generating response...)';
            ragContextDiv.innerHTML = '';
            visualizeSection.style.display = 'none'; // Hide visualize section on new query
            ttsControls.style.display = 'none'; // Hide TTS controls on new query
            listenButton.style.display = 'inline-block'; // Ensure listen button is visible again
            audioPlayer.style.display = 'none'; // Hide audio player
            audioPlayer.src = ''; // Clear previous audio
            document.getElementById('generated-image-container').innerHTML = ''; // Clear old image
            
            // Remove old attribution if it exists
            const oldAttribution = ragAnswerContainer.querySelector('.attribution');
            if (oldAttribution) {
                oldAttribution.remove();
            }

            try {
                const formData = new FormData();
                formData.append('query', query);
                formData.append('model', selectedModel);

                const response = await fetch('/query/rag', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (response.ok) {
                    ragAnswerDiv.textContent = result.answer;

                    // Add attribution
                    const attributionDiv = document.createElement('div');
                    attributionDiv.className = 'attribution';
                    attributionDiv.textContent = `Answer generated by ${selectedModel} in response to the question: "${query}"`;
                    ragAnswerContainer.appendChild(attributionDiv);
                    
                    // Show the visualize and listen sections
                    visualizeSection.style.display = 'block';
                    ttsControls.style.display = 'flex'; // Use flex for better alignment
                    loadComfyModels(); // Load models for the visualize section
                    loadElevenLabsVoices(); // Load voices for TTS

                    // Display the context that was used
                    if (result.context && result.context.length > 0) {
                        ragContextDiv.innerHTML = result.context.map((chunk, index) => `
                            <div class="context-item">
                                <p class="meta">Context Chunk ${index + 1}</p>
                                <p>${chunk.replace(/</g, "&lt;").replace(/>/g, "&gt;")}</p>
                            </div>
                        `).join('');
                    } else {
                        ragContextDiv.innerHTML = '<p>No specific context was retrieved to generate this answer.</p>';
                    }
                    ragStatus.textContent = 'Answer received.';
                } else {
                    throw new Error(result.detail || 'Failed to get RAG answer.');
                }
            } catch (error) {
                ragStatus.textContent = `Error: ${error.message}`;
                ragAnswerDiv.textContent = `Failed to get an answer. ${error.message}`;
            }
        });

        // --- Handle Text-to-Speech ---

        async function loadElevenLabsVoices() {
            try {
                const response = await fetch('/api/elevenlabs/voices');
                if (!response.ok) throw new Error('Failed to fetch ElevenLabs voices.');
                
                const data = await response.json();
                voiceSelect.innerHTML = ''; // Clear previous options
                data.voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.voice_id;
                    option.textContent = voice.name;
                    voiceSelect.appendChild(option);
                });
            } catch (error) {
                console.error('Error fetching ElevenLabs voices:', error);
                voiceSelect.innerHTML = `<option>Error loading voices</option>`;
            }
        }

        listenButton.addEventListener('click', async () => {
            const textToSpeak = ragAnswerDiv.textContent;
            const selectedVoice = voiceSelect.value;
            if (!textToSpeak || !selectedVoice) return;

            listenButton.textContent = 'Generating...';
            listenButton.disabled = true;

            try {
                const formData = new FormData();
                formData.append('text', textToSpeak);
                formData.append('voice_id', selectedVoice);

                const response = await fetch('/api/text-to-speech', {
                    method: 'POST',
                    body: formData
                });

                if (response.ok) {
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayer.src = audioUrl;
                    audioPlayer.style.display = 'block';
                    audioPlayer.play();
                    listenButton.style.display = 'none'; // Hide button, show player
                } else {
                    const error = await response.json();
                    throw new Error(error.detail || 'Failed to generate audio.');
                }
            } catch (error) {
                ragStatus.textContent = `TTS Error: ${error.message}`;
            } finally {
                listenButton.textContent = 'Listen';
                listenButton.disabled = false;
                // On a new query, the whole tts-controls div is hidden and reset,
                // so we don't need to manually re-show the button here.
            }
        });


        // --- Handle Image Generation ---
        
        async function loadComfyModels() {
            const comfyModelsList = document.getElementById('comfy-models-list');
            const visualizeStatus = document.getElementById('visualize-status');
            try {
                visualizeStatus.textContent = 'Fetching image models...';
                const response = await fetch('/api/comfy/models');
                if (!response.ok) throw new Error('Failed to fetch ComfyUI models.');
                
                const data = await response.json();
                comfyModelsList.innerHTML = '';
                data.models.forEach(modelName => {
                    const option = document.createElement('option');
                    option.value = modelName;
                    comfyModelsList.appendChild(option);
                });
                visualizeStatus.textContent = 'Image models loaded.';
            } catch (error) {
                visualizeStatus.textContent = `Error: ${error.message}`;
            }
        }

        const visualizeForm = document.getElementById('visualize-form');
        visualizeForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            const visualizeStatus = document.getElementById('visualize-status');
            const imageContainer = document.getElementById('generated-image-container');
            
            const basePrompt = ragAnswerDiv.textContent;
            const artisticDirection = document.getElementById('artistic-direction-input').value;
            const selectedImageModel = document.getElementById('comfy-model-input').value;
            const selectedLLM = document.getElementById('model-select').value; // Get the selected LLM for prompt generation

            if (!selectedImageModel) {
                visualizeStatus.textContent = 'Please select an image model.';
                return;
            }

            visualizeStatus.textContent = 'Generating new image prompt with AI Art Director...';
            imageContainer.innerHTML = '<p>The AI Art Director is thinking...</p>';

            try {
                // --- Step 1: Generate the new prompt with the AI Art Director ---
                const promptGenFormData = new FormData();
                promptGenFormData.append('base_prompt', basePrompt);
                promptGenFormData.append('artistic_direction', artisticDirection);
                promptGenFormData.append('model', selectedLLM);

                const promptGenResponse = await fetch('/api/generate-image-prompt', {
                    method: 'POST',
                    body: promptGenFormData
                });

                if (!promptGenResponse.ok) {
                    const error = await promptGenResponse.json();
                    throw new Error(`AI Art Director failed: ${error.detail}`);
                }

                const promptGenResult = await promptGenResponse.json();
                const finalPrompt = promptGenResult.new_prompt;

                visualizeStatus.textContent = `Dreaming with ${selectedImageModel}...`;
                imageContainer.innerHTML = `<p>Image generation in progress with new prompt: "<em>${finalPrompt.replace(/</g, "&lt;").replace(/>/g, "&gt;")}</em>"</p>`;

                // --- Step 2: Generate the image with the new prompt ---
                const imageGenFormData = new FormData();
                imageGenFormData.append('prompt', finalPrompt);
                imageGenFormData.append('model', selectedImageModel);

                const imageResponse = await fetch('/api/generate-image', {
                    method: 'POST',
                    body: imageGenFormData
                });

                if (imageResponse.ok) {
                    const imageBlob = await imageResponse.blob();
                    const imageUrl = URL.createObjectURL(imageBlob);
                    imageContainer.innerHTML = `<img id="generated-image" src="${imageUrl}" alt="Generated image based on the AI-enhanced prompt">`;
                    visualizeStatus.textContent = 'Image generated successfully!';
                    
                    // Show image chat interface and store the image URL
                    const imageChatSection = document.getElementById('image-chat-section');
                    imageChatSection.style.display = 'block';
                    imageChatSection.dataset.imageUrl = imageUrl;
                    
                    // Clear previous chat messages
                    document.getElementById('chat-messages').innerHTML = '<p style="color: #666; font-size: 0.9rem; text-align: center; margin: 2rem 0;">Ask me anything about this image! üé®</p>';
                } else {
                    const error = await imageResponse.json();
                    throw new Error(error.detail || 'Image generation failed.');
                }
            } catch (error) {
                visualizeStatus.textContent = `Error: ${error.message}`;
                imageContainer.innerHTML = `<p style="color:red;">${error.message}</p>`;
            }
        });
        
        // --- Handle Image Chat ---
        const imageChatForm = document.getElementById('image-chat-form');
        const chatMessages = document.getElementById('chat-messages');
        const chatMessageInput = document.getElementById('chat-message-input');
        const chatStatus = document.getElementById('chat-status');
        const visionModelSelect = document.getElementById('vision-model-select');
        
        imageChatForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            
            const message = chatMessageInput.value.trim();
            if (!message) return;
            
            const imageChatSection = document.getElementById('image-chat-section');
            const imageUrl = imageChatSection.dataset.imageUrl;
            
            if (!imageUrl) {
                chatStatus.textContent = 'No image available for chat.';
                chatStatus.style.color = 'red';
                return;
            }
            
            // Add user message to chat
            const userMsg = document.createElement('div');
            userMsg.style.cssText = 'background: #667eea; color: white; padding: 0.8rem; border-radius: 8px; margin-bottom: 0.8rem; max-width: 80%; margin-left: auto; text-align: right;';
            userMsg.innerHTML = `<strong>You:</strong> ${message}`;
            chatMessages.appendChild(userMsg);
            chatMessages.scrollTop = chatMessages.scrollHeight;
            
            // Clear input and show loading
            chatMessageInput.value = '';
            chatStatus.textContent = 'ü§î AI is analyzing the image...';
            chatStatus.style.color = '#667eea';
            
            try {
                const response = await fetch('/api/chat-with-image', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        image_url: imageUrl,
                        message: message,
                        model: visionModelSelect.value
                    })
                });
                
                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.detail || 'Chat request failed');
                }
                
                const result = await response.json();
                
                // Add AI response to chat
                const aiMsg = document.createElement('div');
                aiMsg.style.cssText = 'background: white; border: 1px solid #e0e0e0; padding: 0.8rem; border-radius: 8px; margin-bottom: 0.8rem; max-width: 80%;';
                aiMsg.innerHTML = `<strong style="color: #667eea;">ü§ñ AI:</strong><br>${result.response.replace(/\n/g, '<br>')}`;
                chatMessages.appendChild(aiMsg);
                chatMessages.scrollTop = chatMessages.scrollHeight;
                
                chatStatus.textContent = '';
            } catch (error) {
                chatStatus.textContent = `Error: ${error.message}`;
                chatStatus.style.color = 'red';
                
                // Add error message to chat
                const errorMsg = document.createElement('div');
                errorMsg.style.cssText = 'background: #fee; border: 1px solid #fcc; padding: 0.8rem; border-radius: 8px; margin-bottom: 0.8rem; color: #c00;';
                errorMsg.innerHTML = `<strong>Error:</strong> ${error.message}`;
                chatMessages.appendChild(errorMsg);
                chatMessages.scrollTop = chatMessages.scrollHeight;
            }
        });

        // --- Handle PixVerse Video Generation ---
        const pixverseForm = document.getElementById('pixverse-form');
        const pixverseStatus = document.getElementById('pixverse-status');
        const generatedVideoContainer = document.getElementById('generated-video-container');

        pixverseForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            const prompt = document.getElementById('pixverse-prompt-input').value;
            if (!prompt) {
                pixverseStatus.textContent = 'Please enter a video prompt.';
                pixverseStatus.style.color = 'red';
                return;
            }

            pixverseStatus.textContent = 'Sending video generation request...';
            pixverseStatus.style.color = '#333';
            generatedVideoContainer.innerHTML = '';

            try {
                const formData = new FormData();
                formData.append('prompt', prompt);

                const response = await fetch('/api/pixverse/generate-video', {
                    method: 'POST',
                    body: formData,
                });

                const result = await response.json();
                if (!response.ok) {
                    throw new Error(result.detail || 'Failed to start video generation.');
                }

                const videoId = result.video_id;
                pixverseStatus.textContent = `Video generation started with ID: ${videoId}. Polling for status...`;
                
                // Start polling for video status
                pollVideoStatus(videoId);

            } catch (error) {
                pixverseStatus.textContent = `Error: ${error.message}`;
                pixverseStatus.style.color = 'red';
            }
        });
        
        // --- Handle Image-to-Video Generation ---
        const pixverseImageForm = document.getElementById('pixverse-image-form');
        
        // Toggle advanced options
        document.getElementById('toggle-advanced').addEventListener('click', () => {
            const advancedOptions = document.getElementById('advanced-options');
            const toggleIcon = document.getElementById('toggle-icon');
            if (advancedOptions.style.display === 'none') {
                advancedOptions.style.display = 'block';
                toggleIcon.textContent = '‚ñ≤';
            } else {
                advancedOptions.style.display = 'none';
                toggleIcon.textContent = '‚ñº';
            }
        });
        
        pixverseImageForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            const imageInput = document.getElementById('pixverse-image-input');
            const prompt = document.getElementById('pixverse-image-prompt-input').value;
            
            if (!imageInput.files || imageInput.files.length === 0) {
                pixverseStatus.textContent = 'Please select an image first.';
                pixverseStatus.style.color = 'red';
                return;
            }
            
            if (!prompt) {
                pixverseStatus.textContent = 'Please enter a motion prompt.';
                pixverseStatus.style.color = 'red';
                return;
            }

            pixverseStatus.textContent = 'Uploading image and starting generation...';
            pixverseStatus.style.color = '#333';
            generatedVideoContainer.innerHTML = '';

            try {
                const formData = new FormData();
                formData.append('image', imageInput.files[0]);
                formData.append('prompt', prompt);
                formData.append('duration', document.getElementById('duration-select').value);
                formData.append('quality', document.getElementById('quality-select').value);
                formData.append('motion_mode', document.getElementById('motion-mode-select').value);
                formData.append('camera_movement', document.getElementById('camera-movement-select').value);
                formData.append('seed', document.getElementById('seed-input').value);

                const response = await fetch('/api/pixverse/generate-video-from-image', {
                    method: 'POST',
                    body: formData,
                });

                const result = await response.json();
                if (!response.ok) {
                    throw new Error(result.detail || 'Failed to start video generation.');
                }

                const videoId = result.video_id;
                pixverseStatus.textContent = `Image-to-video generation started with ID: ${videoId}. Polling for status...`;
                
                // Start polling for video status
                pollVideoStatus(videoId);

            } catch (error) {
                pixverseStatus.textContent = `Error: ${error.message}`;
                pixverseStatus.style.color = 'red';
            }
        });
        
        // --- Store current video ID for actions ---
        let currentVideoId = null;

        async function pollVideoStatus(videoId) {
            currentVideoId = videoId; // Store for later use
            console.log(`Starting polling for video_id: ${videoId}`);
            const interval = setInterval(async () => {
                try {
                    console.log(`Polling status for video_id: ${videoId}`);
                    const response = await fetch(`/api/pixverse/video-status/${videoId}`);
                    const result = await response.json();
                    
                    console.log('Status response:', result);

                    if (!response.ok) {
                        throw new Error(result.detail || 'Failed to get video status.');
                    }

                    // PixVerse status codes: 1=successful, 5=generating, 6=deleted, 7=moderation failed, 8=generation failed
                    const statusText = result.status === 1 ? 'Completed' : 
                                     result.status === 5 ? 'Generating' : 
                                     result.status === 6 ? 'Deleted' : 
                                     result.status === 7 ? 'Moderation Failed' : 
                                     result.status === 8 ? 'Generation Failed' : `Unknown (${result.status})`;
                    
                    pixverseStatus.textContent = `Status: ${statusText} (Video ID: ${videoId})`;

                    // Check if video is complete (status 1) and has a URL
                    if (result.status === 1 && result.url) {
                        clearInterval(interval);
                        console.log('Video complete! URL:', result.url);
                        pixverseStatus.textContent = 'Video generation complete!';
                        pixverseStatus.style.color = 'green';
                        
                        const video = document.createElement('video');
                        video.src = result.url;
                        video.controls = true;
                        video.style.maxWidth = '100%';
                        video.style.marginTop = '1rem';
                        generatedVideoContainer.innerHTML = '';
                        generatedVideoContainer.appendChild(video);
                        
                        // Show video action buttons
                        document.getElementById('video-actions').style.display = 'block';
                        
                        // Refresh credits after successful generation
                        fetchPixverseCredits();
                    } else if (result.status === 7 || result.status === 8) {
                        clearInterval(interval);
                        console.log('Video generation failed with status:', result.status);
                        pixverseStatus.textContent = `Video generation failed: ${statusText}`;
                        pixverseStatus.style.color = 'red';
                    } else {
                        console.log('Still processing, will poll again in 5 seconds');
                    }
                } catch (error) {
                    clearInterval(interval);
                    console.error('Error during polling:', error);
                    pixverseStatus.textContent = `Error polling for status: ${error.message}`;
                    pixverseStatus.style.color = 'red';
                }
            }, 5000); // Poll every 5 seconds
        }
        
        // --- Fetch TTS Speakers ---
        async function fetchTTSSpeakers() {
            try {
                const response = await fetch('/api/pixverse/tts-speakers');
                if (!response.ok) return;
                
                const data = await response.json();
                const speakerSelect = document.getElementById('tts-speaker');
                
                if (data.data && data.data.length > 0) {
                    // Keep Auto option and add all speakers
                    speakerSelect.innerHTML = '<option value="auto">Auto (Detect from video)</option>';
                    data.data.forEach(speaker => {
                        const option = document.createElement('option');
                        option.value = speaker.speaker_id;
                        option.textContent = speaker.name;
                        speakerSelect.appendChild(option);
                    });
                }
            } catch (error) {
                console.error('Error fetching TTS speakers:', error);
            }
        }
        
        // Fetch TTS speakers on page load
        fetchTTSSpeakers();
        
        // --- Toggle Lip Sync Mode ---
        document.querySelectorAll('input[name="lipSyncMode"]').forEach(radio => {
            radio.addEventListener('change', (e) => {
                const ttsMode = document.getElementById('tts-mode');
                const audioMode = document.getElementById('audio-mode');
                
                if (e.target.value === 'tts') {
                    ttsMode.style.display = 'block';
                    audioMode.style.display = 'none';
                } else {
                    ttsMode.style.display = 'none';
                    audioMode.style.display = 'block';
                }
            });
        });
        
        // --- Handle Video Extension ---
        document.getElementById('extend-video-form').addEventListener('submit', async (e) => {
            e.preventDefault();
            
            if (!currentVideoId) {
                pixverseStatus.textContent = 'No video available to extend.';
                pixverseStatus.style.color = 'red';
                return;
            }
            
            const prompt = document.getElementById('extend-prompt').value;
            if (!prompt) return;
            
            pixverseStatus.textContent = 'Extending video...';
            pixverseStatus.style.color = '#333';
            document.getElementById('video-actions').style.display = 'none';
            
            try {
                const formData = new FormData();
                formData.append('source_video_id', currentVideoId);
                formData.append('prompt', prompt);
                formData.append('duration', '5');
                formData.append('quality', '540p');
                formData.append('motion_mode', 'normal');
                formData.append('seed', '0');
                
                const response = await fetch('/api/pixverse/extend-video', {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                if (!response.ok) {
                    throw new Error(result.detail || 'Failed to extend video');
                }
                
                const newVideoId = result.video_id;
                pixverseStatus.textContent = `Extension started with ID: ${newVideoId}. Polling...`;
                
                // Clear the extend form
                document.getElementById('extend-prompt').value = '';
                
                // Start polling for the extended video
                pollVideoStatus(newVideoId);
                
            } catch (error) {
                pixverseStatus.textContent = `Error: ${error.message}`;
                pixverseStatus.style.color = 'red';
            }
        });
        
        // --- Handle Lip Sync ---
        let uploadedAudioMediaId = null;
        
        document.getElementById('lip-sync-form').addEventListener('submit', async (e) => {
            e.preventDefault();
            
            if (!currentVideoId) {
                pixverseStatus.textContent = 'No video available for lip sync.';
                pixverseStatus.style.color = 'red';
                return;
            }
            
            const mode = document.querySelector('input[name="lipSyncMode"]:checked').value;
            const formData = new FormData();
            formData.append('source_video_id', currentVideoId);
            
            if (mode === 'tts') {
                const text = document.getElementById('tts-text').value;
                const speaker = document.getElementById('tts-speaker').value;
                
                if (!text) {
                    pixverseStatus.textContent = 'Please enter speech text.';
                    pixverseStatus.style.color = 'red';
                    return;
                }
                
                formData.append('lip_sync_tts_content', text);
                formData.append('lip_sync_tts_speaker_id', speaker);
                
            } else {
                // Audio mode - need to upload audio first
                const audioFile = document.getElementById('audio-file').files[0];
                
                if (!audioFile && !uploadedAudioMediaId) {
                    pixverseStatus.textContent = 'Please select an audio file.';
                    pixverseStatus.style.color = 'red';
                    return;
                }
                
                // Upload audio if not already uploaded
                if (audioFile && !uploadedAudioMediaId) {
                    try {
                        pixverseStatus.textContent = 'Uploading audio...';
                        const audioFormData = new FormData();
                        audioFormData.append('file', audioFile);
                        
                        const uploadResponse = await fetch('/api/pixverse/upload-media', {
                            method: 'POST',
                            body: audioFormData
                        });
                        
                        const uploadResult = await uploadResponse.json();
                        if (!uploadResponse.ok) {
                            throw new Error(uploadResult.detail || 'Failed to upload audio');
                        }
                        
                        uploadedAudioMediaId = uploadResult.media_id;
                        document.getElementById('audio-upload-status').textContent = `‚úì Audio uploaded (ID: ${uploadedAudioMediaId})`;
                        document.getElementById('audio-upload-status').style.color = 'green';
                        
                    } catch (error) {
                        pixverseStatus.textContent = `Audio upload error: ${error.message}`;
                        pixverseStatus.style.color = 'red';
                        return;
                    }
                }
                
                formData.append('audio_media_id', uploadedAudioMediaId);
            }
            
            pixverseStatus.textContent = 'Generating lip sync...';
            pixverseStatus.style.color = '#333';
            document.getElementById('video-actions').style.display = 'none';
            
            try {
                const response = await fetch('/api/pixverse/lip-sync', {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                if (!response.ok) {
                    throw new Error(result.detail || 'Failed to generate lip sync');
                }
                
                const newVideoId = result.video_id;
                pixverseStatus.textContent = `Lip sync started with ID: ${newVideoId}. Polling...`;
                
                // Clear forms
                document.getElementById('tts-text').value = '';
                document.getElementById('audio-file').value = '';
                uploadedAudioMediaId = null;
                document.getElementById('audio-upload-status').textContent = '';
                
                // Start polling for the lip sync video
                pollVideoStatus(newVideoId);
                
            } catch (error) {
                pixverseStatus.textContent = `Error: ${error.message}`;
                pixverseStatus.style.color = 'red';
            }
        });
    </script>
</body>
</html>

